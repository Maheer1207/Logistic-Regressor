{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6LeKIbAQMGPx"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from scipy.special import expit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PUS2LHf8LwBk"
      },
      "outputs": [],
      "source": [
        "class logistic_regression(object):\n",
        "\n",
        "    def __init__(self, features, obs, d):\n",
        "        self.features = np.hstack((np.ones((features.shape[0], 1)), features))  # Adds a column for the bias term \n",
        "        self.obs = obs\n",
        "        self.d = d + 1  # Adjust the dimension,d, to account the new biased column added in self.features\n",
        "        self.theta = np.zeros(self.d)  # Initialize theta\n",
        " \n",
        "    def sigmoid_function(self, z):  # Implements the sigmoid activation function\n",
        "        return expit(z) # Calculates (1/(1+exp(-z)))\n",
        "\n",
        "    def cost_function(self, theta): # Computes the cost/loss function for logistic regression\n",
        "        l = len(self.obs)\n",
        "        pred = self.sigmoid_function(np.dot(self.features, theta))\n",
        "        err = -self.obs * np.log(pred) - (1 - self.obs) * np.log(1 - pred)\n",
        "        cost = 1 / l * np.sum(err)\n",
        "        return cost\n",
        "    \n",
        "    def grad_function(self, theta): # Computes the gradient or jacobian of the cost function\n",
        "        l = len(self.obs)\n",
        "        pred = self.sigmoid_function(np.dot(self.features, theta))\n",
        "        grad = 1 / l * np.dot(self.features.T, (pred - self.obs))\n",
        "        return grad\n",
        "\n",
        "    def solve(self):    # Minimizes\n",
        "        result = minimize(fun=lambda theta: self.cost_function(theta), \n",
        "                          x0=self.theta, \n",
        "                          method='L-BFGS-B', \n",
        "                          jac=lambda theta: self.grad_function(theta))\n",
        "        \n",
        "        self.theta = result.x\n",
        "        return self.theta\n",
        "    \n",
        "    def predict(self):  # Generates E[Y|X]in terms of 1 and 0, for the calculated value of theta\n",
        "        estimation = self.sigmoid_function(np.dot(self.features, self.theta))\n",
        "        print(\"Estimation: \")\n",
        "        print(estimation)\n",
        "        return (estimation >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "otS8TT_qNOQ_"
      },
      "outputs": [],
      "source": [
        "#IMPORT DATA HERE\n",
        "features = np.load(\"feature.npy\")\n",
        "obs = np.load(\"obs.npy\")\n",
        "d = 10\n",
        "\n",
        "predictor = logistic_regression(features, obs, d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jVugvqSxNZcv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0626967499993043\n"
          ]
        }
      ],
      "source": [
        "#DO NOT CHANGE THIS CELL\n",
        "\n",
        "tic = timeit.default_timer()\n",
        "\n",
        "#Your solver goes here. Do not add any code here.\n",
        "theta = predictor.solve()\n",
        "\n",
        "toc = timeit.default_timer()\n",
        "\n",
        "print(toc - tic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Theta:\n",
            "[1.41837156e-05 2.65373485e+00 5.61681367e-01 5.27571120e-01\n",
            " 7.78975777e-01 2.99964795e+00 3.16434700e-01 1.15935352e+00\n",
            " 2.40913580e+00 1.09409692e+00 2.05809682e+00]\n",
            "Estimation: \n",
            "[8.98092717e-01 6.34828386e-02 9.99988610e-01 ... 2.12003368e-03\n",
            " 4.30588385e-05 4.38842396e-01]\n",
            "Accuracy: \n",
            "99.9995\n"
          ]
        }
      ],
      "source": [
        "#Calculates the Accuracy of the Model\n",
        "\n",
        "print(\"Theta:\")\n",
        "print(predictor.theta)\n",
        "\n",
        "predictions = predictor.predict()\n",
        "obs_pred = (obs >= 0.5).astype(int)\n",
        "accuracy = np.mean(predictions == obs_pred)\n",
        "print(\"Accuracy: \")\n",
        "print(accuracy * 100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
